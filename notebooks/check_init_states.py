#!/usr/bin/env python3
"""
æ£€æŸ¥ LIBERO åˆå§‹çŠ¶æ€æ–‡ä»¶çš„å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§
"""

import os
import pickle
import numpy as np
from pathlib import Path
import sys

def check_init_file(file_path):
    """æ£€æŸ¥å•ä¸ªåˆå§‹çŠ¶æ€æ–‡ä»¶"""
    results = {
        'file': file_path.name,
        'exists': file_path.exists(),
        'size_kb': 0,
        'num_states': 0,
        'state_keys': [],
        'has_robot_states': False,
        'has_object_states': False,
        'error': None
    }
    
    if not file_path.exists():
        results['error'] = 'File not found'
        return results
    
    try:
        # è·å–æ–‡ä»¶å¤§å°
        results['size_kb'] = file_path.stat().st_size / 1024
        
        # åŠ è½½ pickle æ–‡ä»¶
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        
        # æ£€æŸ¥æ•°æ®ç»“æ„
        if isinstance(data, list):
            results['num_states'] = len(data)
            if len(data) > 0:
                first_state = data[0]
                if isinstance(first_state, dict):
                    results['state_keys'] = list(first_state.keys())
                    
                    # æ£€æŸ¥å…³é”®å­—æ®µ
                    results['has_robot_states'] = 'states' in first_state
                    results['has_object_states'] = 'model' in first_state
                    
                    # è¯¦ç»†æ£€æŸ¥æœºå™¨äººçŠ¶æ€
                    if 'states' in first_state:
                        robot_states = first_state['states']
                        if isinstance(robot_states, (list, np.ndarray)):
                            results['robot_state_dim'] = len(robot_states)
                        else:
                            results['robot_state_type'] = type(robot_states).__name__
                    
                    # æ£€æŸ¥ç‰©ä½“çŠ¶æ€
                    if 'model' in first_state:
                        results['has_model_xml'] = True
                else:
                    results['error'] = f'First state is not dict, got {type(first_state)}'
        else:
            results['error'] = f'Data is not list, got {type(data)}'
            
    except Exception as e:
        results['error'] = str(e)
    
    return results

def analyze_task_suite(suite_name='libero_10_eval'):
    """åˆ†ææ•´ä¸ªä»»åŠ¡å¥—ä»¶çš„åˆå§‹çŠ¶æ€"""
    base_path = Path('/home/whu/LIBERO_PLUS/libero/libero/init_files') / suite_name
    
    print(f"{'='*80}")
    print(f"æ£€æŸ¥ä»»åŠ¡å¥—ä»¶: {suite_name}")
    print(f"è·¯å¾„: {base_path}")
    print(f"{'='*80}\n")
    
    if not base_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {base_path}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ .init å’Œ .pruned_init æ–‡ä»¶
    init_files = sorted(base_path.glob('*.init'))
    pruned_files = sorted(base_path.glob('*.pruned_init'))
    
    print(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  .init æ–‡ä»¶: {len(init_files)}")
    print(f"  .pruned_init æ–‡ä»¶: {len(pruned_files)}")
    print()
    
    # æ£€æŸ¥é…å¯¹
    init_names = {f.stem for f in init_files}
    pruned_names = {f.stem.replace('.pruned', '') for f in pruned_files}
    
    missing_pruned = init_names - pruned_names
    missing_init = pruned_names - init_names
    
    if missing_pruned:
        print(f"âš ï¸  ç¼ºå°‘ .pruned_init çš„ä»»åŠ¡ ({len(missing_pruned)}):")
        for name in sorted(missing_pruned)[:5]:
            print(f"    - {name}")
        if len(missing_pruned) > 5:
            print(f"    ... è¿˜æœ‰ {len(missing_pruned)-5} ä¸ª")
        print()
    
    if missing_init:
        print(f"âš ï¸  ç¼ºå°‘ .init çš„ä»»åŠ¡ ({len(missing_init)}):")
        for name in sorted(missing_init)[:5]:
            print(f"    - {name}")
        if len(missing_init) > 5:
            print(f"    ... è¿˜æœ‰ {len(missing_init)-5} ä¸ª")
        print()
    
    # è¯¦ç»†æ£€æŸ¥å‰3ä¸ªæ–‡ä»¶
    print(f"ğŸ” è¯¦ç»†æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶:\n")
    
    files_to_check = list(pruned_files[:3]) if pruned_files else list(init_files[:3])
    
    for i, file_path in enumerate(files_to_check, 1):
        results = check_init_file(file_path)
        
        print(f"[{i}] {results['file']}")
        print(f"    å¤§å°: {results['size_kb']:.2f} KB")
        print(f"    çŠ¶æ€æ•°é‡: {results['num_states']}")
        
        if results['error']:
            print(f"    âŒ é”™è¯¯: {results['error']}")
        else:
            print(f"    âœ“ æœºå™¨äººçŠ¶æ€: {'æ˜¯' if results['has_robot_states'] else 'å¦'}")
            print(f"    âœ“ ç‰©ä½“æ¨¡å‹: {'æ˜¯' if results['has_object_states'] else 'å¦'}")
            if 'robot_state_dim' in results:
                print(f"    âœ“ çŠ¶æ€ç»´åº¦: {results['robot_state_dim']}")
            if results['state_keys']:
                print(f"    âœ“ å­—æ®µ: {', '.join(results['state_keys'][:5])}")
        print()
    
    # ç»Ÿè®¡åˆ†æ
    print(f"ğŸ“ˆ ç»Ÿè®¡åˆ†æ:")
    
    all_results = [check_init_file(f) for f in pruned_files[:10]]
    
    valid_files = [r for r in all_results if not r['error']]
    error_files = [r for r in all_results if r['error']]
    
    print(f"  æœ‰æ•ˆæ–‡ä»¶: {len(valid_files)}/{len(all_results)}")
    print(f"  é”™è¯¯æ–‡ä»¶: {len(error_files)}/{len(all_results)}")
    
    if valid_files:
        sizes = [r['size_kb'] for r in valid_files]
        state_counts = [r['num_states'] for r in valid_files]
        
        print(f"  å¹³å‡æ–‡ä»¶å¤§å°: {np.mean(sizes):.2f} KB (èŒƒå›´: {np.min(sizes):.2f} - {np.max(sizes):.2f})")
        print(f"  å¹³å‡çŠ¶æ€æ•°: {np.mean(state_counts):.1f} (èŒƒå›´: {np.min(state_counts)} - {np.max(state_counts)})")
    
    if error_files:
        print(f"\nâŒ é”™è¯¯æ–‡ä»¶åˆ—è¡¨:")
        for r in error_files:
            print(f"    - {r['file']}: {r['error']}")
    
    print(f"\n{'='*80}")
    print(f"âœ… æ£€æŸ¥å®Œæˆ!")
    print(f"{'='*80}")

def test_load_with_libero(suite_name='libero_10_eval', task_idx=0):
    """ä½¿ç”¨ LIBERO API æµ‹è¯•åŠ è½½åˆå§‹çŠ¶æ€"""
    print(f"\n{'='*80}")
    print(f"ä½¿ç”¨ LIBERO API æµ‹è¯•åŠ è½½")
    print(f"{'='*80}\n")
    
    try:
        from libero.libero import benchmark
        
        benchmark_dict = benchmark.get_benchmark_dict()
        task_suite = benchmark_dict[suite_name]()
        
        print(f"âœ“ ä»»åŠ¡å¥—ä»¶: {suite_name}")
        print(f"âœ“ ä»»åŠ¡æ€»æ•°: {task_suite.n_tasks}")
        
        task = task_suite.get_task(task_idx)
        print(f"âœ“ æµ‹è¯•ä»»åŠ¡: {task.name}")
        
        init_states = task_suite.get_task_init_states(task_idx)
        print(f"âœ“ åŠ è½½åˆå§‹çŠ¶æ€: {len(init_states)} ä¸ª")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªçŠ¶æ€
        if len(init_states) > 0:
            state = init_states[0]
            print(f"\nåˆå§‹çŠ¶æ€ç»“æ„:")
            if isinstance(state, dict):
                for key in state.keys():
                    value = state[key]
                    if isinstance(value, (list, np.ndarray)):
                        print(f"  {key}: {type(value).__name__} shape={np.array(value).shape}")
                    else:
                        print(f"  {key}: {type(value).__name__}")
        
        print(f"\nâœ… LIBERO API åŠ è½½æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    suite = sys.argv[1] if len(sys.argv) > 1 else 'libero_10_eval'
    
    # åˆ†ææ–‡ä»¶
    analyze_task_suite(suite)
    
    # æµ‹è¯• LIBERO API
    test_load_with_libero(suite, task_idx=0)
